{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd \nimport seaborn as sns\nimport shutil\nimport tensorflow as tf\nfrom glob import glob \n#from google.cloud import storage\nfrom matplotlib import pyplot as plt\nfrom IPython.display import Image, display\nfrom learntools.deep_learning.decode_predictions import decode_predictions\nfrom sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\nfrom tensorflow.keras.applications.xception import preprocess_input\n\n# Cloud Storage\n# from google.cloud import storage\n# storage_client = storage.Client(project='YOUR PROJECT ID')\n\npd.set_option('display.max_colwidth', None)\n\nin_path = '../input/pokemon-generation-one/'\nout_path = './'\n\nimg_size = (512,512)\n\n\n\n# res = prep_images(glob(in_path + 'dataset/Abra/*'), img_size)\n# print(res[0])","metadata":{"_uuid":"3722a2b2-7b8a-4953-845f-c892d8cab9d7","_cell_guid":"b44a7a67-e1dd-475c-ab5d-e5fbf75ec269","execution":{"iopub.status.busy":"2022-01-09T17:45:28.520849Z","iopub.execute_input":"2022-01-09T17:45:28.52166Z","iopub.status.idle":"2022-01-09T17:45:28.532848Z","shell.execute_reply.started":"2022-01-09T17:45:28.521488Z","shell.execute_reply":"2022-01-09T17:45:28.531884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Detect hardware, return appropriate distribution strategy\n# try:\n#     tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n#     print('Running on TPU ', tpu.master())\n# except ValueError:\n#     tpu = None\n\n# if tpu:\n#     tf.config.experimental_connect_to_cluster(tpu)\n#     tf.tpu.experimental.initialize_tpu_system(tpu)\n#     strategy = tf.distribute.experimental.TPUStrategy(tpu)\n# else:\n#     strategy = tf.distribute.get_strategy() # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n\n# print(\"REPLICAS: \", strategy.num_replicas_in_sync)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-01-09T17:45:28.5345Z","iopub.execute_input":"2022-01-09T17:45:28.535163Z","iopub.status.idle":"2022-01-09T17:45:28.542403Z","shell.execute_reply.started":"2022-01-09T17:45:28.53512Z","shell.execute_reply":"2022-01-09T17:45:28.541319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_imgs = pd.Series([ len(glob(x+\"/*\")) for x in glob(in_path+'dataset/*')])\nprint(num_imgs.sum())\nplt.hist(num_imgs)\nplt.xlabel(\"Num Of Imgs\")\nplt.ylabel(\"Frequency\")","metadata":{"execution":{"iopub.status.busy":"2022-01-09T17:45:28.544091Z","iopub.execute_input":"2022-01-09T17:45:28.545147Z","iopub.status.idle":"2022-01-09T17:45:28.804741Z","shell.execute_reply.started":"2022-01-09T17:45:28.545101Z","shell.execute_reply":"2022-01-09T17:45:28.803782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_poke = {n:os.path.basename(x) for n, x in enumerate(sorted(glob(in_path+'dataset/*')))}\nnum_poke.pop(148)\npoke_num = {os.path.basename(x):n for n, x in enumerate(sorted(glob(in_path+'dataset/*')))}\npoke_num.pop('dataset')\nprint(poke_num)","metadata":{"execution":{"iopub.status.busy":"2022-01-09T17:45:28.806163Z","iopub.execute_input":"2022-01-09T17:45:28.80671Z","iopub.status.idle":"2022-01-09T17:45:28.82026Z","shell.execute_reply.started":"2022-01-09T17:45:28.806665Z","shell.execute_reply":"2022-01-09T17:45:28.819189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ls = os.listdir(in_path+'dataset')\nprint(ls)\nprint([x for x in ls if x == 'dataset'])\n\n\nfrom tensorflow.keras import utils\n\nmylist = [1,2,3,4,5,6]\n\nprint(utils.to_categorical(mylist))","metadata":{"execution":{"iopub.status.busy":"2022-01-09T17:45:28.822421Z","iopub.execute_input":"2022-01-09T17:45:28.82308Z","iopub.status.idle":"2022-01-09T17:45:28.839423Z","shell.execute_reply.started":"2022-01-09T17:45:28.823038Z","shell.execute_reply":"2022-01-09T17:45:28.838563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for name, files in all_dirs.items():\n#     print(name)\n    \n#     files = pd.Series([x for x in files if x.endswith(\".jpg\")])\n#     print(files.iloc[0:10])\n    \n#     test_sample = files.sample(5).reset_index(drop=True)\n#     files.drop(test_sample.index, inplace=True)\n#     test_sample.reset_index(drop=True, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-01-09T17:45:28.841122Z","iopub.execute_input":"2022-01-09T17:45:28.841538Z","iopub.status.idle":"2022-01-09T17:45:28.846134Z","shell.execute_reply.started":"2022-01-09T17:45:28.841496Z","shell.execute_reply":"2022-01-09T17:45:28.845098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if os.path.isdir('./test/'):\n    shutil.rmtree('./test/')\nif os.path.isdir('./train/'):\n    shutil.rmtree('./train/')\n\nall_dirs = {os.path.basename(x): glob(x+\"/*\") for x in glob(in_path+'dataset/*') if not x.endswith('dataset')}\n#print(all_dirs)\nos.makedirs(\"./train\", exist_ok=True)\n#os.makedirs(\"./val\", exist_ok=True)\nos.makedirs(\"./test\", exist_ok=True)\n\nnum_imgs = 0\nnonjpg = 0\n\ntrain_id = []\ntrain_label = []\ntest_id = []\ntest_label = []\n\ntrain_img_name = 0\ntest_img_name = 0\n\n\nfor name, files in all_dirs.items():\n    #os.makedirs(\"./train/\"+name, exist_ok=True)\n    #os.makedirs(\"./val/\"+name, exist_ok=True)\n    #os.makedirs(\"./test/\"+name, exist_ok=True)\n    \n    nonjpg += len([x for x in files if not x.endswith(\".jpg\")])\n    train_src = pd.Series([x for x in files if x.endswith(\".jpg\")])\n    \n    num_imgs += len(train_src)\n    \n\n    test_src = train_src.sample(3)\n    test_src.reset_index(drop=True, inplace=True)\n    \n    train_src.drop(test_src.index, inplace=True)\n    train_src.reset_index(drop=True, inplace=True)\n    \n\n#     val_sample = train_src.sample(5)\n#     train_src.drop(val_sample.index, inplace=True)\n#     val_sample.reset_index(drop=True, inplace=True)\n    train_dest = []\n    test_dest = []\n    \n    for i in range(len(train_src)):\n        f = f'{train_img_name}.jpg'\n        shutil.copy2(train_src.iloc[i], f'./train/{f}')\\\n        #shutil.copy2(train_src.iloc[i], f'./train/{name}/{os.path.basename(train_src.iloc[i])}')\n        train_dest += [f'./train/{f}']\n        train_img_name += 1\n    \n    for i in range(len(test_src)):\n        f = f'{test_img_name}.jpg'\n        shutil.copy2(test_src.iloc[i], f'./test/{f}')\n        #shutil.copy2(test_src.iloc[i], f'./test/{name}/{os.path.basename(test_src.iloc[i])}')\n        #shutil.copy2(val_sample.iloc[i], f'./val/{name}/{os.path.basename(val_sample[i])}')\n        test_dest += [f'./test/{f}']\n        test_img_name += 1       \n        \n    train_id += train_dest\n    train_label += [name] * len(train_dest)\n    \n    test_id += test_dest\n    test_label += [name] * len(test_dest)\n\ntrain_df = pd.DataFrame({'filename': train_id, 'class':train_label})\ntest_df = pd.DataFrame({'filename': test_id, 'class':test_label})","metadata":{"execution":{"iopub.status.busy":"2022-01-09T17:50:50.092386Z","iopub.execute_input":"2022-01-09T17:50:50.092779Z","iopub.status.idle":"2022-01-09T17:50:59.909708Z","shell.execute_reply.started":"2022-01-09T17:50:50.092745Z","shell.execute_reply":"2022-01-09T17:50:59.908934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# s = train_df.sample(10)\n# t = test_df.sample(10)\n\n# fig, ax = plt.subplots(10,2, figsize=(9,9))\n\n# for n, ((_,x), (_,y)) in enumerate(zip(s.iterrows(), t.iterrows())):\n#     print(f\"{x['class']},{x['filename']}     {y['class']},{y['filename']}\")\n#     ax[n,0].imshow(load_img(x.filename))\n#     ax[n,1].imshow(load_img(y.filename))\n","metadata":{"execution":{"iopub.status.busy":"2021-11-14T17:04:11.498373Z","iopub.execute_input":"2021-11-14T17:04:11.498669Z","iopub.status.idle":"2021-11-14T17:04:11.504975Z","shell.execute_reply.started":"2021-11-14T17:04:11.49864Z","shell.execute_reply":"2021-11-14T17:04:11.504001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(load_img('./train/8001.jpg'))\nprint(train_df.loc[8001])","metadata":{"execution":{"iopub.status.busy":"2022-01-09T17:53:45.618901Z","iopub.execute_input":"2022-01-09T17:53:45.619225Z","iopub.status.idle":"2022-01-09T17:53:45.770336Z","shell.execute_reply.started":"2022-01-09T17:53:45.619194Z","shell.execute_reply":"2022-01-09T17:53:45.76757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total = 0\n\nfor name, files in all_dirs.items():\n    files = [f for f in files if f.endswith('.jpg')]\n    total += len(files)\n    \nprint(total)\nprint(len(os.listdir(\"./train\")))\nprint(len(os.listdir(\"./train\"))+len(os.listdir(\"./test/\")))","metadata":{"execution":{"iopub.status.busy":"2022-01-09T17:53:51.333299Z","iopub.execute_input":"2022-01-09T17:53:51.333649Z","iopub.status.idle":"2022-01-09T17:53:51.35581Z","shell.execute_reply.started":"2022-01-09T17:53:51.333617Z","shell.execute_reply":"2022-01-09T17:53:51.354821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nonjpgs = []\nfor i in glob(\"./test/*\"):\n    nonjpgs += [x for x in glob(i+\"/*\") if not x.endswith(\".jpg\")]\nprint(nonjpgs)\n\ns = 0\nt = 0\nfor i in glob(\"./test/*\"):\n    s += len(glob(i+\"/*\"))\n# for j in glob(\"./val/*\"):\n#     t += len(glob(j+\"/*\"))\nprint(s)\n# print(t)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-01-09T17:53:57.145562Z","iopub.execute_input":"2022-01-09T17:53:57.145881Z","iopub.status.idle":"2022-01-09T17:53:57.173393Z","shell.execute_reply.started":"2022-01-09T17:53:57.145849Z","shell.execute_reply":"2022-01-09T17:53:57.172734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(os.listdir(\"./train/\")))\n#print(len(os.listdir(\"./val/\")))\nprint(len(os.listdir(\"./test/\")))\n\nn_classes = len(os.listdir(\"./train/\"))\nprint(n_classes)\n\nprint(os.listdir('./train/')[0:20])","metadata":{"execution":{"iopub.status.busy":"2022-01-09T17:53:58.991317Z","iopub.execute_input":"2022-01-09T17:53:58.991682Z","iopub.status.idle":"2022-01-09T17:53:59.017795Z","shell.execute_reply.started":"2022-01-09T17:53:58.99165Z","shell.execute_reply":"2022-01-09T17:53:59.016877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_poke = {n:os.path.basename(x) for n, x in enumerate(sorted(glob(in_path+'dataset/*')))}\nnum_poke.pop(148)\npoke_num = {os.path.basename(x):n for n, x in enumerate(sorted(glob(in_path+'dataset/*')))}\npoke_num.pop('dataset')\n","metadata":{"execution":{"iopub.status.busy":"2022-01-09T17:54:04.803666Z","iopub.execute_input":"2022-01-09T17:54:04.804045Z","iopub.status.idle":"2022-01-09T17:54:04.81935Z","shell.execute_reply.started":"2022-01-09T17:54:04.804008Z","shell.execute_reply":"2022-01-09T17:54:04.818672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import Xception\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, BatchNormalization, GlobalAveragePooling2D\nfrom sklearn.model_selection import KFold\nfrom keras.constraints import max_norm\n","metadata":{"execution":{"iopub.status.busy":"2022-01-09T17:54:06.611778Z","iopub.execute_input":"2022-01-09T17:54:06.612114Z","iopub.status.idle":"2022-01-09T17:54:06.669417Z","shell.execute_reply.started":"2022-01-09T17:54:06.612083Z","shell.execute_reply":"2022-01-09T17:54:06.668664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_classes=149\n#ith strategy.scope():\ndef get_model():\n\n    model = Sequential()\n    model.add(Xception(include_top=False, \n                       pooling='avg',\n                       weights='imagenet', #'../input/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5',\n                       input_shape=tuple((*img_size,3))))\n    model.add(Dropout(0.5))\n    model.add(BatchNormalization())\n    model.add(Dense(n_classes,  activation='softmax'))\n    #optimizer = tf.keras.optimizers.Adam()\n    #optimizer = tf.keras.optimizers.SGD(learning_rate=0.0001)\n    model.compile(optimizer='adam',\n                 loss='categorical_crossentropy',\n                 metrics=['accuracy'])\n    \n    model.layers[0].trainable = False\n    return model\n    \nmodel = get_model()\nprint(model.summary())\n","metadata":{"execution":{"iopub.status.busy":"2022-01-09T17:54:08.818294Z","iopub.execute_input":"2022-01-09T17:54:08.818647Z","iopub.status.idle":"2022-01-09T17:54:13.75142Z","shell.execute_reply.started":"2022-01-09T17:54:08.818615Z","shell.execute_reply":"2022-01-09T17:54:13.750583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EPOCHS = 8\nLR_START = 0.00001\nLR_MAX = 0.0001 \nLR_MIN = 0.00001\nLR_RAMPUP_EPOCHS = 5\nLR_SUSTAIN_EPOCHS = 0\nLR_EXP_DECAY = .8\n\ndef lrfn(epoch):\n    if epoch < LR_RAMPUP_EPOCHS:\n        lr = (LR_MAX - LR_START) / LR_RAMPUP_EPOCHS * epoch + LR_START\n    elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n        lr = LR_MAX\n    else:\n        lr = (LR_MAX - LR_MIN) * LR_EXP_DECAY**(epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS) + LR_MIN\n    return lr\n    \nlr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose = True)\n\nrng = [i for i in range(25 if EPOCHS<25 else EPOCHS)]\ny = [lrfn(x) for x in rng]\nplt.plot(rng, y)\nprint(\"Learning rate schedule: {:.3g} to {:.3g} to {:.3g}\".format(y[0], max(y), y[-1]))","metadata":{"execution":{"iopub.status.busy":"2022-01-09T17:56:46.646345Z","iopub.execute_input":"2022-01-09T17:56:46.646724Z","iopub.status.idle":"2022-01-09T17:56:46.86318Z","shell.execute_reply.started":"2022-01-09T17:56:46.646693Z","shell.execute_reply":"2022-01-09T17:56:46.862237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_batch = 50\nval_batch = 50\n\ndef train_CV(df, folds = 5):\n    data_generator = ImageDataGenerator(preprocess_input,\n                                   horizontal_flip=True,\n                                   rotation_range=20,\n                                   width_shift_range=0.2,\n                                   height_shift_range = 0.2)\n    \n    histories = []\n    models = []\n    \n    kfold = KFold(folds, shuffle=True)\n    \n    for train_idx, val_idx in kfold.split(df):\n               \n        train_gen = data_generator.flow_from_dataframe(dataframe=df.loc[train_idx], \n                                                       directory=None,\n                                                       batch_size=train_batch)\n\n        val_gen = data_generator.flow_from_dataframe(dataframe=df.loc[val_idx],\n                                                     directory=None, \n                                                     batch_size=val_batch)\n                                                     #target_size=tuple((*img_size,3)))\n        train_steps = train_gen.n // train_gen.batch_size\n        val_steps = val_gen.n // val_gen.batch_size\n        \n        \n        model = get_model()\n        history = model.fit_generator(train_gen,\n                                      epochs = EPOCHS,\n                                      steps_per_epoch=train_steps,\n                                      validation_data=val_gen, \n                                      validation_steps=val_steps)\n                                      #callbacks=[lr_callback])\n        histories.append(history)\n        models.append(model)\n        break\n    return histories, models","metadata":{"execution":{"iopub.status.busy":"2022-01-09T17:56:48.537264Z","iopub.execute_input":"2022-01-09T17:56:48.537702Z","iopub.status.idle":"2022-01-09T17:56:48.549882Z","shell.execute_reply.started":"2022-01-09T17:56:48.537661Z","shell.execute_reply":"2022-01-09T17:56:48.548489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"histories, models = train_CV(train_df)","metadata":{"execution":{"iopub.status.busy":"2022-01-09T17:56:51.069307Z","iopub.execute_input":"2022-01-09T17:56:51.069656Z","iopub.status.idle":"2022-01-09T18:31:08.779058Z","shell.execute_reply.started":"2022-01-09T17:56:51.069624Z","shell.execute_reply":"2022-01-09T18:31:08.778086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras import utils \nfrom tensorflow.keras.datasets import cifar10\n\n(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n\nprint(type(x_train))\nprint(x_train[0])\nprint(type(y_train))\nprint(y_train.shape)\n\ny_train = utils.to_categorical(y_train, 10)\ny_test = utils.to_categorical(y_test, 10)\n\nprint(type(y_train))\nprint(y_train.shape)\nprint(y_train[0:10])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit_generator(\n        train_gen,\n        epochs = 8,\n        steps_per_epoch=train_steps,\n        validation_data=val_gen, \n        validation_steps=val_steps)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_df = pd.DataFrame(history.history)\n# Start the plot at epoch 5\nprint(history_df)\nhistory_df.loc[0:, ['loss', 'val_loss']].plot()\nhistory_df.loc[0:, ['accuracy', 'val_accuracy']].plot()\n\nprint((\"Best Validation Loss: {:0.4f}\" +\\\n      \"\\nBest Validation Accuracy: {:0.4f}\")\\\n      .format(history_df['val_loss'].min(), \n              history_df['val_accuracy'].max()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}